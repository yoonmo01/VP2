# 시스템 설계 (System Design)

## 3.1 시스템 개요

본 논문에서 제안하는 VP2(VoicePhish Simulator v2)는 대규모 언어모델(LLM) 기반의 다중 에이전트 보이스피싱 시뮬레이션 플랫폼이다. VP2는 공격자-피해자 간 다회차(multi-turn) 대화를 자동 생성하고, 실시간 감정 분석 및 HMM(Hidden Markov Model) 기반 피해자 상태 추적을 통해 라운드별 적응적 지침(Adaptive Guidance)을 동적으로 생성한다. 최종적으로 피해자 개인 특성에 맞춘 맞춤형 예방 전략을 산출함으로써, 교육·훈련 및 연구 목적의 보이스피싱 대응 역량 강화를 지원한다.

그림 1은 VP2의 전체 시스템 아키텍처를 보여준다. 시스템은 크게 **프론트엔드(React 기반 웹 인터페이스)**, **백엔드 API 서버(FastAPI)**, **MCP 시뮬레이션 서버**, **감정 분석 모듈**, **HMM 상태 추적기**, **동적 지침 생성기**로 구성된다.

```
┌──────────────────────────────────────────────────────────────────┐
│                    프론트엔드 (React + Vite)                      │
│  ┌──────────┐  ┌──────────────┐  ┌───────────┐  ┌───────────┐  │
│  │ 시나리오  │  │  시뮬레이션   │  │  결과 분석 │  │  TTS 재생  │  │
│  │ 선택 화면 │  │  실시간 화면  │  │  리포트   │  │  모달     │  │
│  └──────────┘  └──────────────┘  └───────────┘  └───────────┘  │
│                        │ SSE (Server-Sent Events)                │
└────────────────────────┼─────────────────────────────────────────┘
                         │
┌────────────────────────▼─────────────────────────────────────────┐
│                백엔드 API 서버 (FastAPI)                           │
│  ┌─────────────────────────────────────────────────────────┐     │
│  │           ReAct Agent Orchestrator                      │     │
│  │  ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌───────────┐  │     │
│  │  │MCP Tool  │ │Admin Tool│ │Emotion   │ │Tavily     │  │     │
│  │  │(시뮬레이션)│ │(판정/지침)│ │Tool(감정)│ │Tool(검색) │  │     │
│  │  └─────┬────┘ └────┬─────┘ └────┬─────┘ └─────┬─────┘  │     │
│  └────────┼──────────┼───────────┼──────────────┼──────────┘     │
│           │          │           │              │                 │
│  ┌────────▼──┐ ┌─────▼─────┐ ┌──▼──────────┐  │                 │
│  │MCP Server │ │판정/요약   │ │감정분석모듈  │  │                 │
│  │(대화생성)  │ │LLM 호출   │ │KoELECTRA   │  │                 │
│  └───────────┘ └───────────┘ │+ HMM Runner │  │                 │
│                              └─────────────┘  │                 │
│  ┌──────────────────────────────────────────┐  │                 │
│  │          PostgreSQL (JSONB)              │  │                 │
│  │  Cases │ Logs │ Rounds │ Prevention     │  │                 │
│  └──────────────────────────────────────────┘  │                 │
└────────────────────────────────────────────────┘                 │
                                                   ┌───────────────▼─┐
                                                   │ Tavily Web API  │
                                                   └─────────────────┘
```

**그림 1.** VP2 시스템 아키텍처 전체도


## 3.2 다중 에이전트 오케스트레이션

### 3.2.1 ReAct 에이전트 프레임워크

VP2의 핵심 제어 로직은 LangChain의 ReAct(Reasoning + Acting) 패턴을 기반으로 구현된 에이전트 오케스트레이터(Agent Orchestrator)에 의해 관리된다. 오케스트레이터는 시뮬레이션의 전체 생명주기를 관장하며, 다음과 같은 도구(Tool)들을 조합하여 자율적으로 의사결정한다:

- **MCP Tool**: MCP(Micro Control Panel) 서버를 호출하여 1라운드 분량의 공격자-피해자 대화를 생성한다.
- **Emotion Tool**: 피해자 발화에 대한 감정 라벨링 및 HMM 기반 상태 시퀀스 분석을 수행한다.
- **Admin Tool**: 라운드별 피싱 성공/실패 판정, 위험도 점수 산출, 동적 지침 생성 및 저장을 담당한다.
- **Tavily Tool**: 사용자 정의 시나리오에 대해 웹 검색을 수행하여 맥락 정보를 보강한다.

오케스트레이터는 최소 2라운드에서 최대 5라운드까지 반복적으로 시뮬레이션을 수행하며, 각 라운드의 결과(피싱 성공/실패, 감정 변화 추이, 위험도)를 종합하여 다음 라운드의 전략을 결정한다.

### 3.2.2 다회차 시뮬레이션 루프

시뮬레이션의 각 라운드는 다음과 같은 단계로 구성된다:

**단계 1. 대화 생성 (MCP Simulator)**
MCP 서버 내에서 독립적인 두 LLM 에이전트(공격자, 피해자)가 교대로 발화를 생성한다. 공격자 에이전트에는 사전 정의된 시나리오(공격 유형, 절차, 화법)와 이전 라운드에서 생성된 보완 지침이 시스템 프롬프트로 주입된다. 피해자 에이전트에는 OCEAN 성격 특성, 인구통계 정보, 금융 리터러시 수준이 프로필로 주어진다. 각 라운드당 최대 15턴까지 대화가 진행되며, 조기 종료 조건(피해자의 강한 거부, 공격자의 종료 선언 등)이 충족되면 라운드가 조기 종결된다.

**단계 2. 감정 분석 및 상태 추적**
생성된 대화의 피해자 발화에 대해 HowRU-KoELECTRA 기반 8클래스 감정 분류를 수행한 후, 4클래스(N/F/A/E)로 매핑한다. 매핑된 감정 시퀀스를 Emoti-Shing HMM에 입력하여 Viterbi 디코딩을 통해 피해자의 은닉 상태 경로(V1→V2→V3)를 추정한다.

**단계 3. 라운드 판정 및 전략 설계**
관리 에이전트(Admin Agent)가 대화 로그, 감정 분석 결과, HMM 상태 추이를 종합하여 해당 라운드의 피싱 성공/실패를 판정한다. 판정 결과에 따라:
- **피싱 성공 시**: 피해자용 예방 지침(Type P)을 생성하여 다음 라운드의 피해자 프롬프트에 주입한다.
- **피싱 실패 시**: 공격자 보완 지침(Type A)을 생성하여 다음 라운드의 공격자 프롬프트에 주입한다.

**단계 4. 종료 판단**
오케스트레이터는 현재 라운드 수, 판정 결과, 연속 실패/성공 패턴을 고려하여 시뮬레이션의 계속/종료를 결정한다. 최소 2라운드를 보장하며, 명확한 수렴(피해자의 완전한 방어 또는 공격자의 완전한 성공)이 확인되면 조기 종료한다.

```
┌─────────────────────────────────────────────────────────┐
│                  시뮬레이션 루프                          │
│                                                         │
│  Round 1 ──→ Round 2 ──→ ... ──→ Round N               │
│    │            │                    │                   │
│    ▼            ▼                    ▼                   │
│  [대화생성]   [대화생성]           [대화생성]             │
│  [감정분석]   [감정분석]           [감정분석]             │
│  [판정]       [판정]               [판정]                │
│    │            │                    │                   │
│    ▼            ▼                    ▼                   │
│  지침 생성    지침 생성            최종 평가              │
│  (A or P)     (A or P)            + 맞춤 예방            │
│    │            │                                        │
│    └──주입──→  └──주입──→  ...                           │
└─────────────────────────────────────────────────────────┘
```

**그림 2.** 다회차 적응적 시뮬레이션 루프


## 3.3 감정 분석 및 HMM 기반 피해자 상태 모델링

### 3.3.1 감정 분류 모듈

피해자 발화의 감정 상태를 실시간으로 추적하기 위해, 사전학습된 한국어 감정 분류 모델인 **HowRU-KoELECTRA**를 활용한다. 이 모델은 KoELECTRA 아키텍처에 기반하여 한국어 텍스트를 8개 감정 클래스(기쁨, 설렘, 평범함, 슬픔, 불쾌함, 분노, 두려움, 놀라움)로 분류한다.

보이스피싱 맥락에서의 감정 추적을 위해, 8클래스 분류 결과를 4개의 감정 차원으로 재매핑한다:

| 8클래스 원본 | 4클래스 매핑 | 의미 |
|---|---|---|
| 기쁨, 설렘 | E (Excitement) | 긍정적 관여 |
| 평범함, 슬픔 | N (Neutral) | 중립적 상태 |
| 불쾌함, 분노 | A (Anger/Adversarial) | 적대적 반응 |
| 두려움 | F (Fear) | 공포/불안 반응 |
| 놀라움 | 문맥 기반 동적 결정 | 후처리 규칙 적용 |

특히 **"놀라움"** 감정은 보이스피싱 맥락에서 두려움(위협 단서 존재 시)과 분노(사기 인지 단서 존재 시)를 모두 내포할 수 있으므로, 규칙 기반 후처리(Rule-based Post-processing)를 통해 동적으로 결정한다:

1. **위협 단서 탐지**: 발화 내 기관 사칭 관련 키워드(검찰, 수사, 영장, 체포 등 27개)의 출현 빈도를 산출한다.
2. **분노/거부 단서 탐지**: 사기 인지 및 거부 관련 키워드(사기, 보이스피싱, 거절, 신고 등 27개)의 출현 빈도를 산출한다.
3. **강한 반발 탐지**: 명시적 거부·차단 표현(끊겠습니다, 직접 확인, 경찰에 신고 등 14개)의 존재 여부를 확인한다.
4. 강한 반발이 존재하면 A(Anger), 위협 단서가 우세하면 F(Fear), 분노 단서가 존재하면 A(Anger), 그 외는 N(Neutral)으로 분류한다.

### 3.3.2 Emoti-Shing HMM 상태 추적

4클래스 감정 시퀀스를 관측값으로 하여, Nyassi et al.(2024)이 제안한 Emoti-Shing HMM의 고정 파라미터를 적용한다. 본 모델은 3개의 은닉 상태(V1, V2, V3)를 정의하며, 각 상태는 피해자의 피싱 취약성 수준을 나타낸다:

- **V1 (Initial/Engaged)**: 초기 관여 상태. 공격자의 시나리오에 자연스럽게 반응하는 단계.
- **V2 (Transitional)**: 전이 상태. 의심 또는 불안이 발생하지만 아직 명확한 판단에 이르지 못한 단계.
- **V3 (Critical)**: 임계 상태. 강한 공포 또는 완전한 협조/거부가 나타나는 단계.

**전이 확률 행렬 A** (Table 4, Nyassi et al., 2024):

|  | V1 | V2 | V3 |
|---|---|---|---|
| V1 | 0.22 | 0.44 | 0.33 |
| V2 | 0.22 | 0.33 | 0.44 |
| V3 | 0.22 | 0.33 | 0.44 |

**방출 확률 행렬 B** (Table 5, Nyassi et al., 2024):

|  | Neutral | Anger | Fear | Excitement |
|---|---|---|---|---|
| V1 | 0.24 | 0.28 | 0.16 | 0.32 |
| V2 | 0.24 | 0.28 | 0.16 | 0.32 |
| V3 | 0.31 | 0.23 | 0.15 | 0.31 |

**초기 분포 π**: (1.0, 0.0, 0.0) — 모든 피해자는 V1 상태에서 시작한다.

피해자 턴의 감정 시퀀스 O = (o₁, o₂, ..., o_T)에 대해 **Viterbi 알고리즘**을 적용하여 최적 상태 경로 S* = argmax P(S|O)를 산출하고, **Forward-Backward 알고리즘**을 통해 각 시점별 사후 확률 γ(t, j) = P(S_t = j | O)를 계산한다. V3 비율(V3 ratio = |{t : S*_t = V3}| / T)은 피해자의 전체적인 취약성 수준을 나타내는 핵심 지표로 활용된다.


## 3.4 동적 지침 생성 시스템

### 3.4.1 지침 생성 프로세스

각 라운드 종료 후 생성되는 적응적 지침(Adaptive Guidance)은 시뮬레이션의 핵심 피드백 메커니즘이다. 지침 생성은 AGENT_PLANNER_PROMPT 템플릿에 기반한 LLM 호출을 통해 수행되며, 다음과 같은 구조적 출력을 산출한다:

```json
{
  "phishing": true | false,
  "outcome": "attacker_success | attacker_fail",
  "reasons": ["판정 근거 1", "판정 근거 2", ...],
  "guidance": {
    "type": "P" | "A",
    "category": "institution_impersonation | acquaintance_impersonation | loan_scam | extortion_threat",
    "title": "지침 제목",
    "text": "10~16줄의 실행 지침",
    "sample_lines": ["시뮬레이터용 예시 대사 1", ...],
    "rationale": "지침 선택 근거"
  }
}
```

### 3.4.2 지침 유형 및 주입 전략

생성된 지침은 두 가지 유형으로 분류되며, 각각 다른 대상에게 주입된다:

**예방 지침 (Type P, Prevention Guidance)**
피싱이 성공한 라운드 이후 생성되며, 다음 라운드의 피해자 에이전트 시스템 프롬프트에 추가된다. 이 지침에는 탐지 체크리스트, 방어적 응답 스크립트, 위험 신호 목록이 포함되어, 피해자가 유사한 공격 패턴에 대해 더 효과적으로 대응할 수 있도록 한다.

**공격자 보완 지침 (Type A, Attacker Supplement Guidance)**
피싱이 실패한 라운드 이후 생성되며, 다음 라운드의 공격자 에이전트 시스템 프롬프트에 추가된다. 이 지침에는 대안적 공격 기법, 심리적 압박 전술, 방어 회피 전략이 포함되어, 시뮬레이션의 현실성을 높이고 피해자의 방어 역량을 더욱 엄격하게 테스트한다.

이러한 양방향 적응적 지침 주입 메커니즘을 통해, 시뮬레이션은 라운드가 진행될수록 점진적으로 난이도가 조절되며, 피해자의 실제 방어 능력을 다각도에서 평가할 수 있다.


## 3.5 맞춤형 예방 전략 생성

모든 라운드가 완료된 후, 사후 평가 에이전트(Post-run Assessor)가 전체 시뮬레이션 결과를 종합하여 피해자 개인에게 특화된 맞춤형 예방 전략(Personalized Prevention)을 생성한다. 이 전략은 다음 요소들을 고려하여 산출된다:

1. **시나리오 특성**: 어떤 유형의 공격(기관 사칭, 지인 사칭, 대출 사기 등)이 수행되었는가
2. **피해자 프로필**: OCEAN 성격 특성, 연령대, 금융 리터러시 수준
3. **감정 변화 궤적**: HMM 분석을 통한 취약성 상태 전이 패턴
4. **라운드별 결과 추이**: 지침 주입 전후의 피싱 성공/실패 변화
5. **구체적 취약 지점**: 어떤 공격 기법에 어떤 방식으로 무너졌는가

생성된 맞춤형 예방 전략은 다음과 같은 구조로 데이터베이스에 저장된다:
- **요약(summary)**: 전체 시뮬레이션 결과에 대한 개괄적 분석
- **실행 단계(steps)**: 피해자가 실생활에서 적용할 수 있는 구체적 방어 절차
- **실용 팁(tips)**: 즉시 활용 가능한 짧은 조언
- **개인화 근거(personalization_reason)**: 이 전략이 해당 피해자에게 특별히 필요한 이유


## 3.6 데이터베이스 설계

VP2는 PostgreSQL을 기반으로 하며, JSONB 타입을 적극 활용하여 비정형 데이터의 유연한 저장을 지원한다. 핵심 엔터티는 다음과 같다:

| 엔터티 | 설명 | 주요 필드 |
|---|---|---|
| PhishingOffender | 공격자 페르소나 | name, type, profile(JSONB: steps, purpose, description) |
| Victim | 피해자 프로필 | name, meta(JSONB: age, gender, occupation), knowledge(JSONB: financial_literacy, technical_skill), traits(JSONB: OCEAN 5요인) |
| AdminCase | 시뮬레이션 케이스 | scenario(JSONB), status, last_risk_score(0-100), last_risk_level, last_recommendation |
| ConversationLog | 턴 단위 대화 기록 | case_id, turn_index, role, content, label, emotion, run, guidance_type, guideline |
| ConversationRound | 라운드 단위 집계 | case_id, run, turns(JSONB), ended_by, stats(JSONB) |
| PersonalizedPrevention | 맞춤형 예방 전략 | case_id, offender_id, victim_id, content(JSONB: summary, steps, tips, personalization_reason) |

ConversationLog 테이블에는 (case_id, turn_index) 및 (case_id, run, turn_index) 복합 인덱스가 설정되어 있어, 특정 케이스의 라운드별 대화 조회를 효율적으로 수행할 수 있다.


## 3.7 프론트엔드 인터페이스

프론트엔드는 React 19와 Vite를 기반으로 구현되며, 다음과 같은 주요 화면으로 구성된다:

- **시나리오 선택 화면(LandingPage)**: 사전 정의된 공격자 페르소나와 피해자 프로필을 선택하거나, 사용자 정의 시나리오/피해자를 입력할 수 있다.
- **시뮬레이션 실시간 화면(SimulatorPage)**: SSE(Server-Sent Events)를 통해 에이전트의 행동(tool 호출, 관찰 결과, 진행 상황)을 실시간으로 스트리밍하여 표시한다. SpeakerAvatar 컴포넌트를 통해 발화자를 시각적으로 구분하고, TerminalLog 컴포넌트로 대화 흐름을 실시간 렌더링한다.
- **결과 분석 화면(ReportPage)**: 케이스 요약, 위험도 점수, 감정 변화 궤적 그래프, 맞춤형 예방 전략을 제공한다. Google Cloud TTS를 활용한 대화 음성 재생 기능도 지원한다.


## 3.8 기술 스택 및 구현

VP2의 기술 스택은 다음과 같이 구성된다:

| 계층 | 기술 | 용도 |
|---|---|---|
| 프론트엔드 | React 19, Vite, TailwindCSS | 사용자 인터페이스 |
| 백엔드 | FastAPI, SQLAlchemy, Pydantic | API 서버 및 ORM |
| 데이터베이스 | PostgreSQL 16+ (JSONB) | 영속 데이터 저장 |
| LLM | OpenAI GPT-4.1 (오케스트레이터/판정), GPT-4o-mini (공격자), Gemini 2.5 Flash Lite (피해자) | 대화 및 추론 생성 |
| 에이전트 프레임워크 | LangChain 0.3, LanGraph 0.6 | ReAct 에이전트 구현 |
| 감정 분석 | HowRU-KoELECTRA (HuggingFace Transformers) | 한국어 감정 분류 |
| HMM | Emoti-Shing (Nyassi et al., 2024) 고정 파라미터 | 피해자 상태 추적 |
| 웹 검색 | Tavily API | 시나리오 맥락 보강 |
| TTS | Google Cloud Text-to-Speech | 대화 음성 합성 |
| 실시간 통신 | SSE (Server-Sent Events) | 프론트엔드 스트리밍 |

공격자와 피해자에 서로 다른 LLM을 사용하는 설계는 의도적인 것으로, 공격자에게는 빠르고 효율적인 모델(GPT-4o-mini)을, 피해자에게는 한국어 자연스러움에 강점이 있는 모델(Gemini 2.5 Flash Lite)을 배정함으로써 시뮬레이션의 현실성과 비용 효율성을 동시에 확보한다. 오케스트레이터와 판정 에이전트에는 높은 추론 능력이 요구되므로 GPT-4.1을 사용한다.
