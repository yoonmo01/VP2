# extract_pair_datasets.py
# âœ… ì‹¤í–‰: python extract_pair_datasets.py
#
# ìž…ë ¥:
# - INPUT_PATHê°€ íŒŒì¼ì´ë©´: í•´ë‹¹ íŒŒì¼ 1ê°œ ì²˜ë¦¬
# - INPUT_PATHê°€ í´ë”ë©´: í•˜ìœ„ *.json ì „ë¶€ ì²˜ë¦¬
#
# ì¶œë ¥(ê° ìž…ë ¥ íŒŒì¼ 1ê°œë‹¹ 1:1 ìƒì„±):
#   (1) victim_only_[caseId].jsonl
#   (2) victim_offender_pair_[caseId].jsonl
#   (3) victim_thoughts_pair_[caseId].jsonl
#   (4) victim_offender_thoughts_[caseId].jsonl
#
# caseId ê·œì¹™:
# - ê¸°ë³¸: íŒŒì¼ëª…(stem) ì‚¬ìš©
# - fallback: JSON ë‚´ë¶€ case_id

from __future__ import annotations

import json
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Tuple


# =========================
# ðŸ”§ ì—¬ê¸°ë§Œ ìˆ˜ì •í•˜ë©´ ë¨
# =========================
INPUT_PATH = r"C:\LIT_VP2\VP\scripts\case_json_0122\ok"   # íŒŒì¼ ë˜ëŠ” í´ë”
OUTPUT_DIR = r"C:\LIT_VP2\VP\scripts\datasets_0122"       # ì¶œë ¥ í´ë”

REQUIRE_PREV_OFFENDER = True        # Trueë©´ ì§ì „ offender ì—†ìœ¼ë©´ (2)(4) ìƒ˜í”Œ ìŠ¤í‚µ
REQUIRE_THOUGHTS = True             # Trueë©´ thoughts ì—†ìœ¼ë©´ (3)(4) ìƒ˜í”Œ ìŠ¤í‚µ
THOUGHTS_FALLBACK_TO_TEXT = False   # thoughts ì—†ìœ¼ë©´ victim textë¡œ ëŒ€ì²´(ê¶Œìž¥X)

# (4)ì—ì„œ victim+prev_offender+thoughtsë¥¼ í•œ ë¬¸ìžì—´ì— ì–´ë–»ê²Œ í•©ì¹ ì§€
# - ëª¨ë¸ ìž…ë ¥ì´ text/text_pairë§Œ ë°›ëŠ” êµ¬ì¡°ë¼ë©´, "text_pair"ì— í•©ì³ ë„£ëŠ” ì‹ì´ íŽ¸í•¨
# - ì—¬ê¸°ì„œëŠ” text_pairì— "prev_offender + '\n' + thoughts"ë¡œ í•©ì¹¨
COMBINE_SEPARATOR = "\n"            # offenderì™€ thoughts ì‚¬ì´ êµ¬ë¶„ìž


def load_json(path: Path) -> Dict[str, Any]:
    with path.open("r", encoding="utf-8") as f:
        return json.load(f)


def iter_case_files(input_path: Path) -> Iterable[Path]:
    if input_path.is_file():
        yield input_path
        return
    for p in input_path.rglob("*.json"):
        if p.is_file():
            yield p


def normalize_thoughts(th: Optional[str]) -> Optional[str]:
    if not th:
        return None
    s = str(th).strip()
    if not s:
        return None
    return s


def get_case_id_for_filename(case: Dict[str, Any], case_file: Path) -> str:
    stem = case_file.stem.strip()
    if stem:
        return stem
    cid = case.get("case_id")
    return str(cid) if cid else "unknown_case"


def extract_four_versions(
    case: Dict[str, Any],
    source_file: str,
    require_prev_offender: bool = True,
    require_thoughts: bool = True,
    thoughts_fallback_to_text: bool = False,
) -> Tuple[
    List[Dict[str, Any]],  # rows_victim_only
    List[Dict[str, Any]],  # rows_pair (victim+prev_offender)
    List[Dict[str, Any]],  # rows_thoughts (victim+thoughts)
    List[Dict[str, Any]],  # rows_all (victim+prev_offender+thoughts)
]:
    """
    Returns:
      (1) victim only: victim(text)
      (2) victim + prev offender: victim(text) + prev offender(text_pair)
      (3) victim + thoughts: victim(text) + thoughts(text_pair)
      (4) victim + prev offender + thoughts:
          victim(text) + combined(text_pair = prev_offender + sep + thoughts)
          (ì›í•˜ë©´ êµ¬ì¡°ë¥¼ ë°”ê¿”ì„œ ë³„ë„ í•„ë“œë¡œ ì €ìž¥í•´ë„ ë¨)
    """
    case_id = case.get("case_id")
    timestamp = case.get("timestamp")

    rows_victim_only: List[Dict[str, Any]] = []
    rows_pair: List[Dict[str, Any]] = []
    rows_thoughts: List[Dict[str, Any]] = []
    rows_all: List[Dict[str, Any]] = []

    rounds = case.get("rounds", [])
    for r in rounds:
        run_no = r.get("run_no")
        turns = r.get("turns", [])

        prev_offender_text: Optional[str] = None

        for i, t in enumerate(turns):
            role = t.get("role")
            text = (t.get("text") or "").strip()

            if role == "offender":
                if text:
                    prev_offender_text = text
                continue

            if role != "victim":
                continue

            if not text:
                continue

            # ê³µí†µ ë©”íƒ€
            base_meta = {
                "case_id": case_id,
                "timestamp": timestamp,
                "source_file": source_file,
                "run_no": run_no,
                "turn_index": i,
                "is_convinced": t.get("is_convinced"),
                "victim_gender": t.get("gender"),
                "victim_age_group": t.get("age_group"),
            }

            # ---------- (1) victim only ----------
            rows_victim_only.append({
                "id": f"{case_id}_run{run_no}_turn{i}_victim_only",
                "mode": "victim_only",
                "text": text,
                "text_pair": None,
                **base_meta,
            })

            # ---------- thoughts ì¤€ë¹„ ----------
            thoughts = normalize_thoughts(t.get("thoughts"))
            if thoughts is None and thoughts_fallback_to_text:
                thoughts = text

            # ---------- (2) victim + prev offender ----------
            if prev_offender_text:
                rows_pair.append({
                    "id": f"{case_id}_run{run_no}_turn{i}_pair",
                    "mode": "victim+prev_offender",
                    "text": text,
                    "text_pair": prev_offender_text,
                    **base_meta,
                })
            elif not require_prev_offender:
                rows_pair.append({
                    "id": f"{case_id}_run{run_no}_turn{i}_pair",
                    "mode": "victim+prev_offender",
                    "text": text,
                    "text_pair": None,
                    **base_meta,
                })

            # ---------- (3) victim + thoughts ----------
            if thoughts:
                rows_thoughts.append({
                    "id": f"{case_id}_run{run_no}_turn{i}_thoughts",
                    "mode": "victim+thoughts",
                    "text": text,
                    "text_pair": thoughts,
                    **base_meta,
                })
            elif not require_thoughts:
                rows_thoughts.append({
                    "id": f"{case_id}_run{run_no}_turn{i}_thoughts",
                    "mode": "victim+thoughts",
                    "text": text,
                    "text_pair": None,
                    **base_meta,
                })

            # ---------- (4) victim + prev offender + thoughts ----------
            # ì •ì±…:
            # - prev_offender_textì™€ thoughts ë‘˜ ë‹¤ ìžˆìœ¼ë©´ ìƒì„±
            # - require_* ì˜µì…˜ì— ë”°ë¼ í•˜ë‚˜ê°€ ì—†ì–´ë„ ìƒì„±í• ì§€ ê²°ì •
            has_prev = bool(prev_offender_text)
            has_th = bool(thoughts)

            if has_prev and has_th:
                combined_pair = f"{prev_offender_text}{COMBINE_SEPARATOR}{thoughts}"
                rows_all.append({
                    "id": f"{case_id}_run{run_no}_turn{i}_all",
                    "mode": "victim+prev_offender+thoughts",
                    "text": text,
                    "text_pair": combined_pair,
                    "prev_offender_text": prev_offender_text,  # ë¶„ì„ìš©(ì„ íƒ)
                    "thoughts": thoughts,                      # ë¶„ì„ìš©(ì„ íƒ)
                    **base_meta,
                })
            else:
                # ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ ì—†ìœ¼ë©´, ì˜µì…˜(require_*)ì— ë”°ë¼ ìŠ¤í‚µ/ìƒì„± ê²°ì •
                if require_prev_offender and not has_prev:
                    continue
                if require_thoughts and not has_th:
                    continue

                # ì—¬ê¸°ê¹Œì§€ ì™”ë‹¤ëŠ” ê±´ "ë¶€ì¡±í•´ë„ ìƒì„±" í—ˆìš© ì¼€ì´ìŠ¤
                parts: List[str] = []
                if prev_offender_text:
                    parts.append(prev_offender_text)
                if thoughts:
                    parts.append(thoughts)
                combined_pair = COMBINE_SEPARATOR.join(parts) if parts else None

                rows_all.append({
                    "id": f"{case_id}_run{run_no}_turn{i}_all",
                    "mode": "victim+prev_offender+thoughts",
                    "text": text,
                    "text_pair": combined_pair,
                    "prev_offender_text": prev_offender_text,
                    "thoughts": thoughts,
                    **base_meta,
                })

    return rows_victim_only, rows_pair, rows_thoughts, rows_all


def write_jsonl(rows: List[Dict[str, Any]], output_path: Path) -> None:
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with output_path.open("w", encoding="utf-8") as f:
        for row in rows:
            f.write(json.dumps(row, ensure_ascii=False) + "\n")


def main() -> None:
    input_path = Path(INPUT_PATH)
    out_dir = Path(OUTPUT_DIR)
    out_dir.mkdir(parents=True, exist_ok=True)

    file_count = 0
    total_victim_only = 0
    total_pair_rows = 0
    total_thought_rows = 0
    total_all_rows = 0

    for case_file in iter_case_files(input_path):
        file_count += 1

        try:
            case = load_json(case_file)
        except Exception as e:
            print(f"[SKIP] failed to read {case_file}: {e}")
            continue

        case_id_for_name = get_case_id_for_filename(case, case_file)

        out_victim_only = out_dir / f"victim_only_{case_id_for_name}.jsonl"
        out_pair = out_dir / f"victim_offender_pair_{case_id_for_name}.jsonl"
        out_thoughts = out_dir / f"victim_thoughts_pair_{case_id_for_name}.jsonl"
        out_all = out_dir / f"victim_offender_thoughts_{case_id_for_name}.jsonl"

        rows_victim_only, rows_pair, rows_thoughts, rows_all = extract_four_versions(
            case,
            source_file=str(case_file),
            require_prev_offender=REQUIRE_PREV_OFFENDER,
            require_thoughts=REQUIRE_THOUGHTS,
            thoughts_fallback_to_text=THOUGHTS_FALLBACK_TO_TEXT,
        )

        write_jsonl(rows_victim_only, out_victim_only)
        write_jsonl(rows_pair, out_pair)
        write_jsonl(rows_thoughts, out_thoughts)
        write_jsonl(rows_all, out_all)

        total_victim_only += len(rows_victim_only)
        total_pair_rows += len(rows_pair)
        total_thought_rows += len(rows_thoughts)
        total_all_rows += len(rows_all)

        print(f"[OK] {case_file.name}")
        print(f"     -> {out_victim_only.name} ({len(rows_victim_only)} rows)")
        print(f"     -> {out_pair.name} ({len(rows_pair)} rows)")
        print(f"     -> {out_thoughts.name} ({len(rows_thoughts)} rows)")
        print(f"     -> {out_all.name} ({len(rows_all)} rows)")

    print("\n=== done ===")
    print(f"  input_files: {file_count}")
    print(f"  total victim_only rows:             {total_victim_only}")
    print(f"  total victim+prev_offender rows:    {total_pair_rows}")
    print(f"  total victim+thoughts rows:         {total_thought_rows}")
    print(f"  total victim+offender+thoughts rows:{total_all_rows}")
    print(f"  out_dir: {out_dir}")


if __name__ == "__main__":
    main()
