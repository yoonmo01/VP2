# scripts/run_emotion_howru_koelectra_postprocess.py
# âœ… ì‹¤í–‰: python scripts/run_emotion_howru_koelectra_postprocess.py
#
# ì…ë ¥:
# - INPUT_PATHê°€ íŒŒì¼(.jsonl)ì´ë©´: ê·¸ íŒŒì¼ 1ê°œ ì²˜ë¦¬
# - INPUT_PATHê°€ í´ë”ë©´: (ìŠ¤ìœ„ì¹˜ì— ë”°ë¼) 4ê°€ì§€ ìœ í˜• íŒ¨í„´ì„ ì„ íƒ ì²˜ë¦¬
#
# ì¶œë ¥(1:1):
# - out íŒŒì¼ëª…ì€ "pred_" + ì›ë³¸ íŒŒì¼ëª…
#
# ì§€ì› 4ìœ í˜•:
# (1) victim_only_*.jsonl
# (2) victim_offender_pair_*.jsonl
# (3) victim_thoughts_pair_*.jsonl
# (4) victim_offender_thoughts_*.jsonl
#
# í•µì‹¬:
# - HowRU KoELECTRA ê°ì •ëª¨ë¸(8ê°ì •)ì„ ì‚¬ìš©í•´ì„œ probs8/pred8ì„ ì–»ê³ 
# - í›„ì²˜ë¦¬ ê·œì¹™ìœ¼ë¡œ 4ê°ì •(N/F/A/E)ë¡œ ë³€í™˜
# - íŠ¹íˆ "ë†€ë¼ì›€(Surprise)"ì€ ìœ„í˜‘/ë°˜ë°œ(ê±°ë¶€/ì˜ì‹¬) ë‹¨ì„œë¡œ F/A/N ì¤‘ í•˜ë‚˜ë¡œ ë¶„ê¸°
#
# âœ… ë³€ê²½ì‚¬í•­(ìš”ì²­ ë°˜ì˜):
# - ê¸°ì¡´ì— Eë¡œ ê°€ë˜ ê²ƒ(ê¸°ì¨/ì„¤ë ˜)ì„ Aë¡œ ë³´ëƒ„
# - Surprise ë¶„ê¸°ì—ì„œ reward(ë³´ìƒ) ê¸°ë°˜ ë¶„ê¸°ëŠ” ì œê±°í•˜ê³ , ë°˜ë°œ(anger) ë‹¨ì„œë¡œ A ë¶„ê¸°
# - âœ… ì¼€ì´ìŠ¤ íë¦„ ë°˜ì˜ ë£° ê°•í™”:
#   - "ê°•í•œ ë°˜ë°œ(ì‚¬ê¸° í™•ì‹ /ëŠê¸°/ì§ì ‘ í™•ì¸/ê°•í•œ ê±°ì ˆ)" ë‹¨ì„œê°€ ìˆìœ¼ë©´ A ìš°ì„ 
#   - ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ threat_scoreê°€ "ì¶©ë¶„íˆ ê°•í•  ë•Œ"(>=3) + threat>angerì¼ ë•Œ F
#   - ë‚˜ë¨¸ì§€ëŠ” anger_score>=1ì´ë©´ A, ì•„ë‹ˆë©´ N
# - âœ… SURPRISE_MIN_PROBë¥¼ ì˜¬ë ¤ì„œ(0.20) ë†€ë¼ì›€ í™•ë¥ ì´ ì¶©ë¶„í•  ë•Œë§Œ ë¶„ê¸° ì ìš©(ë¡œê·¸ í˜¼ë€ ê°ì†Œ)

from __future__ import annotations

import json
import os
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Tuple

import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# Windowsì—ì„œ ê²½ê³  ì¤„ì´ê¸°(ì„ íƒ)
os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"
os.environ["TRANSFORMERS_NO_ADVISORY_WARNINGS"] = "1"

# =========================
# ğŸ”§ ì—¬ê¸°ë§Œ ìˆ˜ì •í•˜ë©´ ë¨
# =========================
INPUT_PATH = r"C:\LIT_VP2\VP\scripts\datasets_0122"                 # íŒŒì¼(.jsonl) ë˜ëŠ” í´ë”
OUTPUT_DIR = r"C:\LIT_VP2\VP\scripts\emotion_result_koelectra"     # ì¶œë ¥ í´ë”

# âœ… ìŠ¤ìœ„ì¹˜: ì›í•˜ëŠ” ê²ƒë§Œ Trueë¡œ ì¼œê¸° (4ê°€ì§€ ìœ í˜•)
RUN_VICTIM_ONLY = False            # victim_only_*.jsonl
RUN_OFFENDER_PAIR = True           # victim_offender_pair_*.jsonl
RUN_THOUGHTS_PAIR = False          # victim_thoughts_pair_*.jsonl
RUN_OFFENDER_THOUGHTS = False      # victim_offender_thoughts_*.jsonl

BATCH_SIZE = 16
MAX_LENGTH = 512  # ëª¨ë¸ ì¹´ë“œ/ì˜ˆì‹œê°€ 512 ì‚¬ìš©. ë¹„êµ ì‹¤í—˜ì´ë©´ ì—¬ê¸° ê³ ì • ì¶”ì²œ.

# âœ… HowRU KoELECTRA ê°ì •ëª¨ë¸(8-class)
MODEL_ID = "LimYeri/HowRU-KoELECTRA-Emotion-Classifier"
TOKENIZER_ID = "LimYeri/HowRU-KoELECTRA-Emotion-Classifier"

# âœ… ì¶œë ¥ì— labels8(ë¼ë²¨ ìˆœì„œ)ê¹Œì§€ ë„£ì„ì§€(í–‰ë§ˆë‹¤ ë°˜ë³µ ì €ì¥ë˜ë¯€ë¡œ ìš©ëŸ‰ ì¦ê°€)
INCLUDE_LABELS8_IN_EACH_ROW = False

# =========================
# âœ… 8 -> 4 ë§¤í•‘ (ìš”ì²­ ë°˜ì˜)
# =========================
# ê¸°ì¨(Joy), ì„¤ë ˜(Excitement) -> âœ… A(Anger)  (ê¸°ì¡´ Eì˜€ìŒ)
# í‰ë²”í•¨(Neutral), ìŠ¬í””(Sadness) -> N(Neutral)
# ë¶ˆì¾Œí•¨(Disgust), ë¶„ë…¸(Anger) -> A(Anger)
# ë‘ë ¤ì›€(Fear) -> F(Fear)
# ë†€ë¼ì›€(Surprise) -> ê·œì¹™ìœ¼ë¡œ F/A/N ë¶„ê¸°
MAP_8_TO_4_BASE = {
    "ê¸°ì¨": "A",      # âœ… ë³€ê²½: E -> A
    "ì„¤ë ˜": "A",      # âœ… ë³€ê²½: E -> A
    "í‰ë²”í•¨": "N",
    "ìŠ¬í””": "N",
    "ë¶ˆì¾Œí•¨": "A",
    "ë¶„ë…¸": "A",
    "ë‘ë ¤ì›€": "F",
    "ë†€ë¼ì›€": None,  # í›„ì²˜ë¦¬ ê·œì¹™ì—ì„œ ê²°ì •
}

# =========================
# "ë†€ë¼ì›€" ë¶„ê¸° ì˜µì…˜
# =========================
HANDLE_SURPRISE = True

# - ìœ„í˜‘/ìœ„ê¸° ë‹¨ì„œ: Fear(F)ë¡œ ë³´ëƒ„
THREAT_CUES = [
    "ê²€ì°°", "ê²€ì‚¬", "ìˆ˜ì‚¬", "ê²½ì°°", "ê¸ˆê°ì›", "ê¸ˆìœµê°ë…ì›", "ì§€ê²€", "ì§€ì²­",
    "ì—°ë£¨", "ë²”ì£„", "í˜ì˜", "í”¼ì˜ì", "ê³ ì†Œ", "ê³ ë°œ", "ì˜ì¥", "ì²´í¬", "êµ¬ì†",
    "ì••ìˆ˜", "ëª°ìˆ˜", "ì†¡ì¹˜", "ê¸°ì†Œ", "ì¬íŒ", "ë²Œê¸ˆ", "ì²˜ë²Œ",
    "ë™ê²°", "ì •ì§€", "ì°¨ë‹¨", "ê±°ë˜ì •ì§€", "ê³„ì¢Œì •ì§€", "ëŒ€í¬í†µì¥",
    "ìœ„í—˜", "ê¸´ê¸‰", "ì¦‰ì‹œ", "ì˜¤ëŠ˜ ì•ˆì—", "ì§€ê¸ˆ ë‹¹ì¥", "í°ì¼", "ë¬¸ì œ",
]

# - ë°˜ë°œ/ê±°ë¶€/ì˜ì‹¬ ë‹¨ì„œ: Anger(A)ë¡œ ë³´ëƒ„
#   (ê¸°ê´€ì‚¬ì¹­ ë°ì´í„°ì—ì„œëŠ” 'ë³´ìƒ/ì´ë“' í‚¤ì›Œë“œê°€ ì˜¤íˆë ¤ ë…¸ì´ì¦ˆë¼ ì œê±°)
ANGER_CUES = [
    # ì˜ì‹¬/ì‚¬ê¸° ì¸ì§€
    "ì‚¬ê¸°", "ë³´ì´ìŠ¤í”¼ì‹±", "ê±°ì§“", "ê°€ì§œ", "ìˆ˜ìƒ", "ì´ìƒí•˜", "ë§ì´ ì•ˆ", "ë§ë„ ì•ˆ",
    "ë¯¿ì„ ìˆ˜", "ì˜ì‹¬", "í™•ì¸í• ê²Œ", "ì§ì ‘ í™•ì¸", "ì§ì ‘ ì—°ë½", "ë°©ë¬¸í•´ì„œ",
    # ê±°ë¶€/ëŠê¸°/ê°•í•œ ê±°ì ˆ
    "ëª» ë“œë¦¬", "ì•ˆ ë“œë¦¬", "ì ˆëŒ€", "ê±°ì ˆ", "ë¶ˆê°€ëŠ¥", "ê·¸ë§Œ", "ì¤‘ë‹¨", "ë” ì´ìƒ",
    "ëŠê² ", "ëŠìŠµë‹ˆë‹¤", "ì „í™” ëŠ", "í†µí™” ì¢…ë£Œ",
    # ê³µê²©/í•­ì˜/ì‹ ê³ 
    "ì™œ", "ì§œì¦", "í™”ê°€", "í™”ë‚¬", "ë¶ˆì¾Œ", "ê¸°ë¶„ ë‚˜ì˜", "í˜‘ë°•", "ê°•ìš”",
    "ì‹ ê³ ", "ê²½ì°°ì— ì‹ ê³ ", "ë…¹ìŒ", "ì¦ê±°",
    # ê°œì¸ì •ë³´/ìœ„í—˜ ê²½ê³ (ê±°ë¶€ ë‰˜ì•™ìŠ¤ì¼ ë•Œ)
    "ê°œì¸ì •ë³´", "ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸", "ê³„ì¢Œë²ˆí˜¸", "ë¹„ë°€ë²ˆí˜¸", "ìœ„í—˜", "ë¶€ë‹´ìŠ¤ëŸ½",
]

# âœ… ê°•í•œ ë°˜ë°œ(Reactance) ë‹¨ì„œ: threat í‚¤ì›Œë“œê°€ ê°™ì´ ë– ë„ A ìš°ì„ 
STRONG_REACTANCE_CUES = [
    "ì‚¬ê¸°", "ë³´ì´ìŠ¤í”¼ì‹±", "ê°€ì§œ", "ê±°ì§“",
    "ëª» ë“œë¦¬", "ì•ˆ ë“œë¦¬", "ì ˆëŒ€", "ê±°ì ˆ", "ë¶ˆê°€ëŠ¥",
    "ëŠê² ", "ëŠìŠµë‹ˆë‹¤", "ì „í™” ëŠ", "í†µí™” ì¢…ë£Œ",
    "ì§ì ‘ í™•ì¸", "ì§ì ‘ ì—°ë½", "ë°©ë¬¸í•´ì„œ", "ë°©ë¬¸í•˜", "ì°¾ì•„ê°€",
    "ì‹ ê³ ", "ê²½ì°°ì— ì‹ ê³ ", "ë…¹ìŒ", "ì¦ê±°",
]

# Surprise ë¶„ê¸° ì„ê³„ê°’(í‚¤ì›Œë“œ ì ìˆ˜ ê¸°ë°˜)
# - threat_scoreê°€ ì´ ê°’ ì´ìƒì´ë©´ (ì¡°ê±´ë¶€) F
SURPRISE_THREAT_MIN_SCORE = 3
# - anger_scoreê°€ ì´ ê°’ ì´ìƒì´ë©´ Aë¡œ ë¶„ê¸°(ë‹¨, ì•„ë˜ ë£° ìš°ì„ ìˆœìœ„ ì ìš©)
SURPRISE_ANGER_MIN_SCORE = 1

# âœ… ë†€ë¼ì›€ í™•ë¥ ì´ ì¶©ë¶„í•  ë•Œë§Œ ë¶„ê¸° ì ìš©(ë¡œê·¸ í˜¼ë€ ê°ì†Œ)
SURPRISE_MIN_PROB = 0.20


def load_lines(path: Path) -> List[Dict[str, Any]]:
    rows: List[Dict[str, Any]] = []
    for line in path.read_text(encoding="utf-8").splitlines():
        line = line.strip()
        if not line:
            continue
        rows.append(json.loads(line))
    return rows


def write_jsonl(rows: List[Dict[str, Any]], path: Path) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    with path.open("w", encoding="utf-8") as f:
        for r in rows:
            f.write(json.dumps(r, ensure_ascii=False) + "\n")


def get_target_globs() -> List[str]:
    """ìŠ¤ìœ„ì¹˜ì— ë”°ë¼ í´ë” ì…ë ¥ ì‹œ ì²˜ë¦¬í•  íŒŒì¼ íŒ¨í„´ ê²°ì •"""
    globs: List[str] = []
    if RUN_VICTIM_ONLY:
        globs.append("victim_only_*.jsonl")
    if RUN_OFFENDER_PAIR:
        globs.append("victim_offender_pair_*.jsonl")
    if RUN_THOUGHTS_PAIR:
        globs.append("victim_thoughts_pair_*.jsonl")
    if RUN_OFFENDER_THOUGHTS:
        globs.append("victim_offender_thoughts_*.jsonl")
    return globs


def iter_input_files(input_path: Path) -> Iterable[Path]:
    """
    - íŒŒì¼ì´ë©´ ê·¸ íŒŒì¼ 1ê°œ
    - í´ë”ë©´ ìŠ¤ìœ„ì¹˜ì— ë”°ë¼ íƒ€ê²Ÿ íŒ¨í„´ íŒŒì¼ë“¤ì„ ì¬ê·€ì ìœ¼ë¡œ ì „ë¶€ ë°˜í™˜
    """
    if input_path.is_file():
        yield input_path
        return
    if not input_path.exists():
        return
    for pat in get_target_globs():
        for p in input_path.rglob(pat):
            if p.is_file():
                yield p


def output_path_for_input(in_file: Path, out_dir: Path) -> Path:
    """ì¶œë ¥ íŒŒì¼ëª…: pred_ + ì›ë³¸ íŒŒì¼ëª…"""
    return out_dir / f"pred_{in_file.name}"


def _contains_any(text: str, cues: List[str]) -> int:
    """ë‹¨ìˆœ í‚¤ì›Œë“œ í¬í•¨ ê°œìˆ˜(ì ìˆ˜)"""
    t = (text or "").lower()
    score = 0
    for w in cues:
        if w.lower() in t:
            score += 1
    return score


def _has_any(text: str, cues: List[str]) -> bool:
    """í‚¤ì›Œë“œ í•˜ë‚˜ë¼ë„ í¬í•¨ ì—¬ë¶€"""
    t = (text or "").lower()
    for w in cues:
        if w.lower() in t:
            return True
    return False


def decide_surprise_to_4(text: str, text_pair: Optional[str]) -> Tuple[str, Dict[str, int]]:
    """
    Surprise(ë†€ë¼ì›€)ì„ 4ê°ì •(F/A/N) ì¤‘ ì–´ë””ë¡œ ë³´ë‚¼ì§€ ê²°ì • (ì¼€ì´ìŠ¤ íë¦„ ë°˜ì˜)
    ìš°ì„ ìˆœìœ„:
    1) ê°•í•œ ë°˜ë°œ ë‹¨ì„œê°€ ìˆìœ¼ë©´ A
    2) threatê°€ ì¶©ë¶„íˆ ê°•í•˜ê³ (threat>=3) threat > angerì´ë©´ F
    3) anger_scoreê°€ 1 ì´ìƒì´ë©´ A
    4) ê·¸ ì™¸ N
    """
    combined = (text or "")
    if text_pair:
        combined = combined + "\n" + str(text_pair)

    threat_score = _contains_any(combined, THREAT_CUES)
    anger_score = _contains_any(combined, ANGER_CUES)
    strong_reactance = _has_any(combined, STRONG_REACTANCE_CUES)

    if strong_reactance:
        return "A", {"threat_score": threat_score, "anger_score": anger_score}

    if threat_score >= SURPRISE_THREAT_MIN_SCORE and threat_score > anger_score:
        return "F", {"threat_score": threat_score, "anger_score": anger_score}

    if anger_score >= SURPRISE_ANGER_MIN_SCORE:
        return "A", {"threat_score": threat_score, "anger_score": anger_score}

    return "N", {"threat_score": threat_score, "anger_score": anger_score}


def probs8_to_probs4_with_postprocess(
    probs8: List[float],
    labels8: List[str],
    text: str,
    text_pair: Optional[str],
) -> Dict[str, Any]:
    """
    8ê°œ í™•ë¥ (probs8) -> 4ê°œ í™•ë¥ (probs4=[P(N),P(F),P(A),P(E)]) ë³€í™˜
    - Surprise(ë†€ë¼ì›€) í™•ë¥ ì€ ê·œì¹™ìœ¼ë¡œ F/A/N ì¤‘ í•˜ë‚˜ì— "ì „ë¶€" ë”í•¨
    """
    pN = 0.0
    pF = 0.0
    pA = 0.0
    pE = 0.0

    p_surprise = 0.0
    surprise_idx = None

    for i, p in enumerate(probs8):
        lab8 = labels8[i]

        if lab8 == "ë†€ë¼ì›€":
            p_surprise = p
            surprise_idx = i
            continue

        lab4 = MAP_8_TO_4_BASE.get(lab8)
        if lab4 == "N":
            pN += p
        elif lab4 == "F":
            pF += p
        elif lab4 == "A":
            pA += p
        elif lab4 == "E":
            pE += p
        else:
            # ì˜ˆìƒ ë°– ë¼ë²¨ì´ë©´ ì•ˆì „í•˜ê²Œ Nìœ¼ë¡œ
            pN += p

    surprise_to = None
    cue_scores = {"threat_score": 0, "anger_score": 0}

    if surprise_idx is not None:
        # âœ… ë†€ë¼ì›€ í™•ë¥ ì´ ì¶©ë¶„í•  ë•Œë§Œ ë¶„ê¸°(ë¡œê·¸ í˜¼ë€ ê°ì†Œ)
        if (not HANDLE_SURPRISE) or (p_surprise < SURPRISE_MIN_PROB):
            surprise_to = "N"
            cue_scores = {"threat_score": 0, "anger_score": 0}
        else:
            surprise_to, cue_scores = decide_surprise_to_4(text, text_pair)

        if surprise_to == "N":
            pN += p_surprise
        elif surprise_to == "F":
            pF += p_surprise
        elif surprise_to == "A":
            pA += p_surprise
        elif surprise_to == "E":
            pE += p_surprise
        else:
            pN += p_surprise

    # ì •ê·œí™”
    s = pN + pF + pA + pE
    if s > 0:
        pN, pF, pA, pE = pN / s, pF / s, pA / s, pE / s

    probs4 = [pN, pF, pA, pE]
    pred4 = ["N", "F", "A", "E"][int(torch.tensor(probs4).argmax().item())]

    return {
        "pred4": pred4,
        "probs4": probs4,
        "surprise_to": surprise_to,
        "cue_scores": cue_scores,
        "p_surprise": p_surprise,  # ë””ë²„ê¹…ìš©(ì›í•˜ë©´ ìœ ì§€, ì‹«ìœ¼ë©´ ì§€ì›Œë„ ë¨)
    }


def predict_one(
    model,
    tokenizer,
    device,
    labels8: List[str],
    text: str,
    text_pair: Optional[str],
    max_length: int,
) -> Dict[str, Any]:
    text = (text or "").strip()
    if not text:
        return {"_skip": True}

    if text_pair is not None:
        text_pair = str(text_pair).strip()
        if not text_pair:
            text_pair = None

    if text_pair is None:
        enc = tokenizer(
            text,
            truncation=True,
            max_length=max_length,
            return_tensors="pt",
        )
    else:
        enc = tokenizer(
            text,
            text_pair=text_pair,
            truncation=True,
            max_length=max_length,
            return_tensors="pt",
        )

    enc = {k: v.to(device) for k, v in enc.items()}

    with torch.no_grad():
        logits = model(**enc).logits[0]  # (8,)
        probs8 = torch.softmax(logits, dim=-1).detach().cpu().tolist()
        pred_id = int(torch.argmax(logits).item())

    pred8 = labels8[pred_id]
    pp = probs8_to_probs4_with_postprocess(probs8, labels8, text, text_pair)

    out: Dict[str, Any] = {
        "pred8": pred8,
        "probs8": probs8,   # labels8 ìˆœì„œëŒ€ë¡œ
        "pred4": pp["pred4"],
        "probs4": pp["probs4"],
        "surprise_to": pp["surprise_to"],
        "cue_scores": pp["cue_scores"],
        "p_surprise": pp["p_surprise"],
    }
    if INCLUDE_LABELS8_IN_EACH_ROW:
        out["labels8"] = labels8
    return out


def run_one_file(
    model,
    tokenizer,
    device,
    labels8: List[str],
    in_path: Path,
    out_path: Path,
    batch_size: int,
    max_length: int,
) -> Tuple[int, int]:
    rows = load_lines(in_path)
    out_rows: List[Dict[str, Any]] = []

    bs = max(1, int(batch_size))
    for start in range(0, len(rows), bs):
        batch = rows[start:start + bs]
        for b in batch:
            result = predict_one(
                model=model,
                tokenizer=tokenizer,
                device=device,
                labels8=labels8,
                text=b.get("text", ""),
                text_pair=b.get("text_pair"),
                max_length=max_length,
            )
            if result.get("_skip"):
                continue
            out = dict(b)
            out.update(result)
            out_rows.append(out)

    write_jsonl(out_rows, out_path)
    return len(rows), len(out_rows)


def main() -> None:
    if not (RUN_VICTIM_ONLY or RUN_OFFENDER_PAIR or RUN_THOUGHTS_PAIR or RUN_OFFENDER_THOUGHTS):
        print("[error] RUN_* ìŠ¤ìœ„ì¹˜ ì¤‘ ìµœì†Œ 1ê°œëŠ” Trueì—¬ì•¼ í•©ë‹ˆë‹¤.")
        return

    input_path = Path(INPUT_PATH)
    out_dir = Path(OUTPUT_DIR)
    out_dir.mkdir(parents=True, exist_ok=True)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"[info] device={device}")

    tokenizer = AutoTokenizer.from_pretrained(
        TOKENIZER_ID,
        use_fast=True,
        trust_remote_code=True,
    )

    model = AutoModelForSequenceClassification.from_pretrained(
        MODEL_ID,
        trust_remote_code=True,
    )
    model.to(device)
    model.eval()

    # âœ… ë¼ë²¨ ìˆœì„œ(ëª¨ë¸ config ê¸°ë°˜) -> probs8 í•´ì„ì— ì‚¬ìš©
    id2label = model.config.id2label
    labels8 = [id2label[i] if isinstance(id2label, dict) else None for i in range(model.config.num_labels)]
    if labels8[0] is None:
        labels8 = [id2label[str(i)] for i in range(model.config.num_labels)]

    print(f"[info] labels8_order={labels8}")

    patterns = get_target_globs()
    print(f"[info] patterns: {patterns}")

    files = list(iter_input_files(input_path))
    if not files:
        print(f"[warn] no input files found: {input_path}")
        print(f"       patterns: {patterns}")
        return

    total_in = 0
    total_out = 0

    for in_file in files:
        out_file = output_path_for_input(in_file, out_dir)

        in_n, out_n = run_one_file(
            model=model,
            tokenizer=tokenizer,
            device=device,
            labels8=labels8,
            in_path=in_file,
            out_path=out_file,
            batch_size=BATCH_SIZE,
            max_length=MAX_LENGTH,
        )

        total_in += in_n
        total_out += out_n

        print(f"[done] {in_file.name}")
        print(f"       in={in_n} out={out_n}")
        print(f"       -> {out_file.name}")

    print("\n=== all done ===")
    print(f"  files: {len(files)}")
    print(f"  total_in_rows:  {total_in}")
    print(f"  total_out_rows: {total_out}")
    print(f"  output_dir: {out_dir}")


if __name__ == "__main__":
    main()
