# app/services/prompt_integrator_db.py
from __future__ import annotations
from typing import Dict, Any, Optional
from sqlalchemy.orm import Session
from app.schemas.simulation_request import SimulationStartRequest
from app.db import models as m
import os
from fastapi import HTTPException

ATTACKER_TEMPLATE_NAME = "ATTACKER_PROMPT_V1"
VICTIM_TEMPLATE_NAME   = "VICTIM_PROMPT_V1"

SAFETY_LINE = (
    "[ê·œì¹™] ì‹¤ì œ ê¸°ê´€/ê³„ì¢Œ/ì „í™”ë²ˆí˜¸/ë§í¬ëŠ” ê¸ˆì§€(ê°€ëª…/ë”ë¯¸ë§Œ ì‚¬ìš©). "
    "ì•± ì„¤ì¹˜/ë§í¬ ìš”êµ¬ëŠ” ëª…ì‹œì  ë¬¸ì¥ìœ¼ë¡œë§Œ í‘œí˜„.\n"
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ í‹¸: ë”ë¯¸ ê°’/ìŠ¤í‚¤ë§ˆ ì”ì—¬ë¬¼ ì •ë¦¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _is_dummy(x: Any) -> bool:
    return isinstance(x, str) and x.strip().lower() == "string"

def _clean_text(x: Any) -> str:
    return "" if _is_dummy(x) else (x or "")

def _strip_schema_dummy(d: Any) -> Any:
    # {"additionalProp1": {}} ê°™ì€ ìŠ¤í‚¤ë§ˆ ë”ë¯¸ ì œê±°
    if isinstance(d, dict) and list(d.keys()) == ["additionalProp1"]:
        return {}
    return d

def _is_effectively_empty(d: Any) -> bool:
    """ë¹ˆ dict, ë”ë¯¸(string/additionalProp1)ë§Œ ìˆëŠ” ê²½ìš° True"""
    if not d or not isinstance(d, dict):
        return True
    for _, v in d.items():
        if v in (None, "", {}, [], {"additionalProp1": {}}):
            continue
        if _is_dummy(v):
            continue
        return False
    return True

def _norm_scenario(raw: Dict[str, Any]) -> Dict[str, Any]:
    raw = raw or {}
    desc    = _clean_text(raw.get("description") or raw.get("text"))
    purpose = _clean_text(raw.get("purpose") or raw.get("type"))
    steps   = raw.get("steps") or raw.get("objectives") or []
    if not isinstance(steps, list):
        steps = []
    steps = [s for s in steps if isinstance(s, str) and not _is_dummy(s)]
    return {"description": desc, "purpose": purpose, "steps": steps}

def _norm_victim_profile(raw: Dict[str, Any]) -> Dict[str, Any]:
    raw = raw or {}
    return {
        "meta":      _strip_schema_dummy(raw.get("meta")      or {}),
        "knowledge": _strip_schema_dummy(raw.get("knowledge") or {}),
        "traits":    _strip_schema_dummy(raw.get("traits")    or {}),
    }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DB ë¡œë”©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_victim_profile(db: Session, req: SimulationStartRequest) -> Dict[str, Any]:
    # ë¹ˆ customì´ë©´ ë¬´ì‹œí•˜ê³  DB ì¡°íšŒ
    if getattr(req, "custom_victim", None) and not _is_effectively_empty(req.custom_victim):
        cv = req.custom_victim
        if hasattr(cv, "model_dump"):
            cv = cv.model_dump()
        return _norm_victim_profile(cv)

    assert req.victim_id is not None, "victim_idê°€ í•„ìš”í•©ë‹ˆë‹¤(ì»¤ìŠ¤í…€ í”¼í•´ì ì—†ìŒ)."
    vic = db.get(m.Victim, int(req.victim_id))
    if not vic:
        raise HTTPException(400, detail=f"victim_id={req.victim_id} not found")
    if not getattr(vic, "is_active", True):
        raise HTTPException(400, detail=f"victim_id={req.victim_id} is not active")

    return _norm_victim_profile({
        "meta": vic.meta or (getattr(vic, "body", {}) or {}).get("meta", {}),
        "knowledge": vic.knowledge or (getattr(vic, "body", {}) or {}).get("knowledge", {}),
        "traits": vic.traits or (getattr(vic, "body", {}) or {}).get("traits", {}),
    })

def load_scenario_from_offender(db: Session, offender_id: int) -> Dict[str, Any]:
    off = db.get(m.PhishingOffender, int(offender_id))
    if not off:
        raise HTTPException(400, detail=f"offender_id={offender_id} not found")
    if not getattr(off, "is_active", True):
        raise HTTPException(400, detail=f"offender_id={offender_id} is not active")

    prof = off.profile or {}
    # description ìš°ì„ ìˆœìœ„: name > type > profile.description/text > ê¸°ë³¸
    description = (off.name or off.type or prof.get("description") or prof.get("text") or "ì¼ë°˜ ì‹œë‚˜ë¦¬ì˜¤")
    purpose     = prof.get("purpose") or "ë¯¸ìƒ"
    steps       = prof.get("steps") or []
    if not isinstance(steps, list):
        steps = [str(steps)] if steps else []

    base = {"description": description, "purpose": purpose, "steps": steps}
    return _norm_scenario(base)

def build_custom_scenario(seed: Dict[str, Any], tavily_out: Optional[Dict[str, Any]]) -> Dict[str, Any]:
    # tavily ì¶œë ¥ ìš°ì„ , seed ë³´ì™„
    scn = {
        "description": (tavily_out or {}).get("description") or seed.get("text") or seed.get("type") or "ì»¤ìŠ¤í…€ ì‹œë‚˜ë¦¬ì˜¤",
        "purpose":     (tavily_out or {}).get("purpose")     or seed.get("purpose") or "ë¯¸ìƒ",
        "steps":       (tavily_out or {}).get("steps")       or seed.get("objectives") or [],
    }
    return _norm_scenario(scn)

def save_custom_scenario_to_attack(db: Session, scenario: Dict[str, Any]) -> int:
    """
    ì»¤ìŠ¤í…€ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ Attack ì¹´íƒˆë¡œê·¸ì— ì €ì¥.
    body í•„ë“œì— í†µì§¸ë¡œ ë„£ê³  titleì€ description ì•ë¶€ë¶„ì„ ì‚¬ìš©.
    """
    title = str(scenario.get("description") or "custom").strip()
    atk = m.Attack(title=title[:150] or "custom", category="custom", body=scenario, is_active=True)
    db.add(atk); db.commit(); db.refresh(atk)
    return int(atk.id)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í”„ë¡¬í”„íŠ¸ ìƒì„± + í†µì§œ í”„ë¡¬í”„íŠ¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _build_attacker_prompt(scn: Dict[str, Any], guidance: Optional[Dict[str, str]]) -> str:
    step_lines = "\n".join(f"- {s}" for s in (scn.get("steps") or [])) or "(ì—†ìŒ)"
    g = ""
    if guidance and (guidance.get("type") or "").upper() == "A" and guidance.get("text"):
        g = f"\n[ì§€ì¹¨-ê³µê²©ì]\n{guidance['text']}\n"
    return (
        "[ë³´ì´ìŠ¤í”¼ì‹± ì‹œë®¬ë ˆì´ì…˜]\n"
        f"{SAFETY_LINE}"
        f"[ì‹œë‚˜ë¦¬ì˜¤]\n{scn.get('description') or '(ì„¤ëª… ì—†ìŒ)'}\n"
        f"[ëª©ì ]\n{scn.get('purpose') or '(ëª©ì  ì—†ìŒ)'}\n"
        f"[í˜„ì¬ ë‹¨ê³„ ëª©ë¡]\n{step_lines}\n"
        "[ì—­í• ] ë„ˆëŠ” ê³µê²©ì(í”¼ì‹±ë²”)ë‹¤. í˜„ì¬ ë‹¨ê³„ ë²”ìœ„ ì•ˆì—ì„œë§Œ ë§í•˜ê³ , ì‹¤ì œ ì •ë³´ëŠ” ìƒì„±í•˜ì§€ ë§ˆë¼."
        + g
    )

def _build_victim_prompt(vpf: Dict[str, Any], guidance: Optional[Dict[str, str]]) -> str:
    g = ""
    if guidance and (guidance.get("type") or "").upper() == "P" and guidance.get("text"):
        g = f"\n[ì§€ì¹¨-í”¼í•´ì]\n{guidance['text']}\n"
    return (
        "[ë³´ì´ìŠ¤í”¼ì‹± ì‹œë®¬ë ˆì´ì…˜]\n"
        f"{SAFETY_LINE}"
        "[í”¼í•´ì í”„ë¡œíŒŒì¼]\n"
        f"ë©”íƒ€: {vpf.get('meta')}\n"
        f"ì§€ì‹: {vpf.get('knowledge')}\n"
        f"ì„±ê²©: {vpf.get('traits')}\n"
        "[ì—­í• ] ë„ˆëŠ” í”¼í•´ìë‹¤. í˜„ì‹¤ì  ëŒ€ì‘ì„ í•˜ë˜ ì‹¤ì œ ê°œì¸ì •ë³´/ê³„ì¢Œ/ë§í¬/ë²ˆí˜¸ëŠ” ë§Œë“¤ì§€ ë§ˆë¼."
        + g
    )

def _combine(ap: str, vp: str) -> str:
    # MCP ì„œë²„ ë¶„ë¦¬ê¸°(_split_combined_prompt)ê°€ ì¸ì‹í•˜ëŠ” ë§ˆì»¤
    return f"[ATTACKER]\n{ap}\n[/ATTACKER]\n[VICTIM]\n{vp}\n[/VICTIM]"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë‹¨ì¼ ì§„ì…ì : í”„ë¡¬í”„íŠ¸ íŒ¨í‚¤ì§€ + MCP arguments ìƒì„±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_prompt_package_from_payload(
    db: Session,
    req: SimulationStartRequest,
    tavily_result: Optional[Dict[str, Any]] = None,
    *,
    is_first_run: bool = False,
    skip_catalog_write: bool = True,
    enable_scenario_enhancement: bool = True
) -> Dict[str, Any]:
    victim_profile = load_victim_profile(db, req)

    # ì‹œë‚˜ë¦¬ì˜¤ ë¡œë”©
    if getattr(req, "custom_scenario", None):
        seed = req.custom_scenario.model_dump()
        scenario = build_custom_scenario(seed, tavily_result)
        if is_first_run and not skip_catalog_write:
            _ = save_custom_scenario_to_attack(db, scenario)
    else:
        assert req.offender_id is not None
        scenario = load_scenario_from_offender(db, req.offender_id)

    # ğŸ”¥ ì‹œë‚˜ë¦¬ì˜¤ ê°œì„  ì ìš©
    if enable_scenario_enhancement and is_first_run:
        from app.services.inhanced_scenario_builder import ScenarioEnhancer
        enhancer = ScenarioEnhancer()
        scenario = enhancer.enhance_scenario_with_guidance(
            db=db, base_scenario=scenario, victim_profile=victim_profile)

    # ì§€ì¹¨ ì •ê·œí™”
    guidance = None
    if getattr(req, "guidance", None):
        g = req.guidance
        if hasattr(g, "model_dump"):
            g = g.model_dump()
        if isinstance(g, dict):
            guidance = {"type": (g.get("type") or "").upper(), "text": g.get("text") or ""}

    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    attacker_prompt = getattr(req, "attacker_prompt", None)
    victim_prompt   = getattr(req, "victim_prompt", None)
    if not attacker_prompt or not victim_prompt:
        from app.services.prompt_integrator_db import _build_attacker_prompt, _build_victim_prompt, _combine
        attacker_prompt = _build_attacker_prompt(scenario, guidance)
        victim_prompt   = _build_victim_prompt(victim_profile, guidance)

    from app.services.prompt_integrator_db import _combine
    combined_prompt = _combine(attacker_prompt, victim_prompt)

    # ëª¨ë¸/í„´ìˆ˜
    attacker_model = (getattr(req, "models", {}) or {}).get("attacker") or os.getenv("ATTACKER_MODEL","gpt-4o-mini")
    victim_model   = (getattr(req, "models", {}) or {}).get("victim")   or os.getenv("VICTIM_MODEL","gpt-4o-mini")
    max_turns      = getattr(req, "max_turns", None) or 15

    # MCP ì¸ì êµ¬ì„±
    mcp_args = {
        "offender_id": req.offender_id,
        "victim_id": req.victim_id,
        "scenario": scenario,
        "victim_profile": victim_profile,
        "templates": {"attacker": attacker_prompt, "victim": victim_prompt},
        "combined_prompt": combined_prompt,
        "max_turns": max_turns,
        "models": {"attacker": attacker_model, "victim": victim_model},
    }
    if getattr(req, "case_id_override", None):
        mcp_args["case_id_override"] = str(req.case_id_override)
    if getattr(req, "round_no", None):
        mcp_args["round_no"] = int(req.round_no)
    if guidance:
        mcp_args["guidance"] = guidance
    mcp_args["attacker_prompt"] = attacker_prompt
    mcp_args["victim_prompt"]   = victim_prompt

    return {
        "scenario": scenario,
        "victim_profile": victim_profile,
        "templates": {"attacker": attacker_prompt, "victim": victim_prompt},
        "attacker_prompt": attacker_prompt,
        "victim_prompt": victim_prompt,
        "combined_prompt": combined_prompt,
        "attacker_model": attacker_model,
        "victim_model": victim_model,
        "max_turns": max_turns,
        "mcp_args": mcp_args,
    }

